# RocksDB CLI Docker Environment Configuration
# Copy this file to .env and fill in your values

# ===========================================
# Web Server Configuration
# ===========================================
WEB_PORT=8090
DB_PATH=./data
CONFIG_PATH=./config

# ===========================================
# AI/LLM Configuration
# ===========================================

# LLM Provider: openai, anthropic, azureopenai, google, ollama
GRAPHCHAIN_LLM_PROVIDER=openai

# LLM Model (examples below)
# OpenAI: gpt-4, gpt-4-turbo, gpt-3.5-turbo
# Anthropic: claude-3-opus-20240229, claude-3-sonnet-20240229
# Azure OpenAI: your-deployment-name
# Google: gemini-pro
# Ollama: llama2, mistral, etc.
GRAPHCHAIN_LLM_MODEL=gpt-4

# API Key (required for OpenAI, Anthropic, Google)
# Leave empty for Ollama (local)
GRAPHCHAIN_API_KEY=

# Base URL (optional, for custom endpoints)
# OpenAI: https://api.openai.com/v1
# Ollama: http://ollama:11434 (if using docker-compose)
GRAPHCHAIN_BASE_URL=

# ===========================================
# Azure OpenAI Configuration (if using Azure)
# ===========================================
GRAPHCHAIN_AZURE_ENDPOINT=
GRAPHCHAIN_AZURE_DEPLOYMENT=
GRAPHCHAIN_AZURE_API_VERSION=2024-02-01

# ===========================================
# Security Configuration
# ===========================================

# Read-only mode (prevents write operations)
GRAPHCHAIN_READ_ONLY=false

# Enable audit logging
GRAPHCHAIN_ENABLE_AUDIT=true

# ===========================================
# Legacy Environment Variables (DEPRECATED - for backward compatibility only)
# ===========================================
# ⚠️  DEPRECATED: These variables are kept for backward compatibility only.
# ⚠️  Please migrate to GRAPHCHAIN_API_KEY instead.
# ⚠️  These will be removed in a future version.
#
# Migration guide:
# - If using OpenAI: Set GRAPHCHAIN_API_KEY instead of OPENAI_API_KEY
# - If using Azure OpenAI: Set GRAPHCHAIN_API_KEY instead of AZURE_OPENAI_API_KEY
#
OPENAI_API_KEY=
AZURE_OPENAI_API_KEY=

# ===========================================
# Ollama Configuration (if using local Ollama)
# ===========================================
OLLAMA_PORT=11434

# ===========================================
# Example Configurations
# ===========================================

# --- OpenAI ---
# GRAPHCHAIN_LLM_PROVIDER=openai
# GRAPHCHAIN_LLM_MODEL=gpt-4
# GRAPHCHAIN_API_KEY=sk-...

# --- Anthropic Claude ---
# GRAPHCHAIN_LLM_PROVIDER=anthropic
# GRAPHCHAIN_LLM_MODEL=claude-3-opus-20240229
# GRAPHCHAIN_API_KEY=sk-ant-...

# --- Azure OpenAI ---
# GRAPHCHAIN_LLM_PROVIDER=azureopenai
# GRAPHCHAIN_LLM_MODEL=gpt-4
# GRAPHCHAIN_API_KEY=your-azure-key
# GRAPHCHAIN_AZURE_ENDPOINT=https://your-resource.openai.azure.com
# GRAPHCHAIN_AZURE_DEPLOYMENT=your-deployment-name
# GRAPHCHAIN_AZURE_API_VERSION=2024-02-01

# --- Google Gemini ---
# GRAPHCHAIN_LLM_PROVIDER=google
# GRAPHCHAIN_LLM_MODEL=gemini-pro
# GRAPHCHAIN_API_KEY=your-google-api-key

# --- Ollama (Local) ---
# GRAPHCHAIN_LLM_PROVIDER=ollama
# GRAPHCHAIN_LLM_MODEL=llama2
# GRAPHCHAIN_BASE_URL=http://ollama:11434
# GRAPHCHAIN_API_KEY=  # Leave empty for Ollama
